
#  TransferLearning - Segmentaci√≥n de Prendas con Transfer Learning usando Mask R-CNN y DeepFashion2

---

## ‚ùì Planteamiento del Problema

En el campo de la visi√≥n por computadora, una de las tareas m√°s relevantes para la industria de la moda y el comercio electr√≥nico es la **segmentaci√≥n precisa de prendas de vestir**. Sin embargo, los modelos tradicionales de detecci√≥n de objetos suelen limitarse a la predicci√≥n de cajas delimitadoras (*bounding boxes*), sin capturar el contorno real de la prenda ni su forma pixelada.

Esto representa una gran limitaci√≥n en aplicaciones donde se requiere:

- **Separar con precisi√≥n distintas partes del cuerpo humano seg√∫n la prenda**
- **Clasificar prendas con mayor sem√°ntica que simplemente "ropa"**
- **Extraer m√°scaras que permitan aplicar filtros, reconocimiento o comparaci√≥n visual**

Por ello, surge la necesidad de construir un sistema de segmentaci√≥n por instancia que no solo detecte prendas, sino que identifique y **separe de manera precisa la parte superior (*upper*) y la parte inferior (*lower*)** del atuendo de una persona, a nivel de p√≠xel.

---

## üéØ Objetivos del Proyecto

### Objetivo General

> Desarrollar un sistema de segmentaci√≥n sem√°ntica de prendas de vestir utilizando *Transfer Learning* con Mask R-CNN, que permita detectar y diferenciar la **parte superior** y la **parte inferior** de la ropa en im√°genes del dataset DeepFashion2.

---

### Objetivos Espec√≠ficos

1. **Aplicar t√©cnicas de Transfer Learning** sobre un modelo Mask R-CNN preentrenado para adaptarlo a un nuevo conjunto de clases: `upper` y `lower`.

2. **Preparar y reestructurar el dataset DeepFashion2** para su uso en PyTorch, creando una divisi√≥n clara en `train`, `val` y `test`, y simplificando las clases originales en dos macrocategor√≠as sem√°nticas.

3. **Construir una clase `Dataset` personalizada** que permita leer las anotaciones en formato JSON, extraer m√°scaras por p√≠xel a partir de pol√≠gonos y generar etiquetas compatibles con Mask R-CNN.

4. **Entrenar y validar el modelo modificado**, utilizando m√©tricas de p√©rdida y segmentaci√≥n, comparando el desempe√±o con diferentes tama√±os de datos y √©pocas de entrenamiento.

5. **Visualizar cualitativamente las predicciones del modelo**, mostrando las m√°scaras segmentadas y las etiquetas proyectadas sobre im√°genes reales.


## üß™ Preprocesamiento y Preparaci√≥n del Dataset DeepFashion2

El dataset DeepFashion2, si bien es uno de los m√°s completos para tareas de moda, no viene listo para usarse directamente con modelos como Mask R-CNN. A continuaci√≥n, se detallan todas las transformaciones realizadas para dejarlo en un formato √≥ptimo para el entrenamiento.

---

### üìÅ 1. Reorganizaci√≥n de Carpeta y Estructura de Datos

El dataset original fue reorganizado en una estructura tipo COCO con divisiones expl√≠citas:

```
deepfashion2_coco/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îî‚îÄ‚îÄ annos/
‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îî‚îÄ‚îÄ annos/
‚îî‚îÄ‚îÄ test/
    ‚îú‚îÄ‚îÄ images/
    ‚îî‚îÄ‚îÄ annos/
```

> üìå **C√≥digo clave**: Se utiliz√≥ `shutil.copy()` para mover im√°genes y anotaciones con nombres coincidentes (`image.jpg` y `image.json`).

---

### üîç 2. Filtrado de Muestras V√°lidas

- Se conservaron solo im√°genes que **ten√≠an su anotaci√≥n JSON correspondiente**.
- Se aplic√≥ un **l√≠mite de im√°genes** (`max_images`) para permitir pruebas r√°pidas.
- Las im√°genes fueron barajadas aleatoriamente con `random.shuffle()` para garantizar aleatoriedad en la divisi√≥n.

```python
image_files = list(images_path.glob("*.jpg"))
random.seed(42)
random.shuffle(image_files)
```

---

### üßæ 3. Reducci√≥n de Categor√≠as a Upper y Lower

Se cre√≥ un `category_map` que agrupa las 13 categor√≠as originales en solo 2 clases sem√°nticas:

```python
category_map = {
    "short sleeve top": "upper",
    "long sleeve top": "upper",
    "short sleeve outwear": "upper",
    "long sleeve outwear": "upper",
    "vest": "upper",
    "sling": "upper",
    "dress": "upper",
    "shorts": "lower",
    "trousers": "lower",
    "skirt": "lower"
}
```

- Las clases fueron reetiquetadas internamente como: `1 = upper`, `2 = lower`

---

### üß† 4. Creaci√≥n de M√°scaras Binarias

Cada pol√≠gono de segmentaci√≥n del `.json` fue convertido a una m√°scara por p√≠xel usando OpenCV:

```python
mask = np.zeros((height, width), dtype=np.uint8)
polygon = np.array(seg[0], dtype=np.int32).reshape(-1, 2)
cv2.fillPoly(mask, [polygon], color=1)
```

Esto permiti√≥ que el modelo aprendiera **qu√© p√≠xeles pertenecen a la prenda** y cu√°les no.

---

### üß∞ 5. Dataset Personalizado para PyTorch

Se implement√≥ la clase `DeepFashionDataset`, compatible con `torch.utils.data.Dataset`. Esta clase:

- Carga im√°genes con `PIL.Image`
- Lee los `.json` y convierte cajas, etiquetas y m√°scaras a tensores
- Aplica transformaciones (`ToTensor`) para normalizar las entradas

```python
image, target = dataset[idx]
target = {
    "boxes": Tensor[n, 4],
    "labels": Tensor[n],
    "masks": Tensor[n, H, W],
    "image_id": Tensor[1]
}
```

> üìå Esta clase fue usada tanto para entrenamiento como para validaci√≥n, permitiendo flexibilidad total.

---

### ‚ö†Ô∏è 6. Control de Errores y Datos Vac√≠os

- Se ignoraron objetos sin `bounding_box` o sin `segmentation` v√°lida.
- Se devolvieron tensores vac√≠os si la imagen no conten√≠a ninguna instancia v√°lida.
- Esto evit√≥ errores en tiempo de entrenamiento con el modelo Mask R-CNN.

---

### üëÅÔ∏è 7. Visualizaci√≥n de Muestras Anotadas

Se implement√≥ una funci√≥n `show_random_samples()` para inspecci√≥n visual del dataset:

- Dibuja las `bounding boxes` en verde
- Superpone las m√°scaras en rojo con transparencia
- Muestra la etiqueta (`upper` o `lower`) sobre cada objeto detectado

> üì∏ **Recomendaci√≥n**: Inserta capturas de esta funci√≥n en acci√≥n. Puedes usar una diapositiva como:  
> ‚ÄúImagen segmentada desde el dataset‚Äù del PDF de presentaci√≥n.

---

### ‚úÖ Estado Final del Dataset

- Dataset dividido, filtrado y validado
- M√°scaras por p√≠xel listas para segmentaci√≥n
- Etiquetas reducidas a `upper` y `lower`
- Dataset 100% compatible con `Mask R-CNN`


## üß† Definici√≥n del Modelo y Aplicaci√≥n de Transfer Learning

Para resolver la tarea de segmentaci√≥n sem√°ntica de prendas de vestir, se utiliz√≥ el modelo **Mask R-CNN** con backbone **ResNet-50 + Feature Pyramid Network (FPN)**, preentrenado sobre el dataset COCO.

A continuaci√≥n, se describe c√≥mo se adapt√≥, entren√≥ y evalu√≥ el modelo para el contexto espec√≠fico del proyecto.

---

### üì¶ Carga y Adaptaci√≥n del Modelo Preentrenado

Se carg√≥ el modelo `maskrcnn_resnet50_fpn(pretrained=True)` y se congelaron las capas del backbone para preservar el conocimiento aprendido sobre caracter√≠sticas visuales generales:

```python
model = maskrcnn_resnet50_fpn(pretrained=True)
for name, param in model.backbone.body.named_parameters():
    param.requires_grad = False  # se pueden descongelar si se desea un fine-tuning completo
```

Luego, se reemplazaron dos cabezas importantes:

1. **Box Predictor**: se reemplaz√≥ para adaptarse al n√∫mero de clases personalizado (`background`, `upper`, `lower`):

```python
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
```

2. **Mask Predictor**: se reemplaz√≥ para predecir m√°scaras por p√≠xel para las nuevas clases:

```python
in_mask_features = model.roi_heads.mask_predictor.conv5_mask.in_channels
model.roi_heads.mask_predictor = MaskRCNNPredictor(in_mask_features, 256, num_classes)
```

---

### ‚öôÔ∏è Configuraci√≥n del Entrenamiento

- **Dispositivo**: se utiliz√≥ GPU si estaba disponible (`cuda`) o CPU como fallback.
- **√âpocas**: 5
- **Batch size**: 4 para entrenamiento, 2 para validaci√≥n y test
- **Optimizador**: SGD con momentum y regularizaci√≥n:

```python
optimizer = SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)
```

---

### üîÅ Ciclo de Entrenamiento por √âpoca

Durante cada √©poca se entren√≥ el modelo y luego se evalu√≥ en el conjunto de validaci√≥n.

#### Entrenamiento:

```python
for images, targets in train_loader:
    images = [img.to(device) for img in images]
    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

    loss_dict = model(images, targets)
    losses = sum(loss for loss in loss_dict.values())

    optimizer.zero_grad()
    losses.backward()
    optimizer.step()
```

#### Evaluaci√≥n:

Despu√©s de cada √©poca, se evalu√≥ el modelo con IoU y p√©rdida sobre el conjunto de validaci√≥n. Se guard√≥ el mejor modelo (`best_val_loss`) con `torch.save()`.

```python
val_acc, val_loss = evaluate_model(model, val_loader, device)
```

---

### üìä Evaluaci√≥n Final en Test

Despu√©s del entrenamiento completo, se carg√≥ el mejor modelo guardado y se evalu√≥ sobre el conjunto de prueba (`test_loader`).

```python
model.load_state_dict(torch.load(save_path))
test_acc, test_loss = evaluate_model(model, test_loader, device)
```

M√©trica principal: **IoU promedio por objeto (threshold 0.5)**

---

### üìà Visualizaci√≥n de Resultados

Se graficaron las siguientes curvas para monitorear el entrenamiento:

- `Train Loss` vs. `Val Loss`
- `Val Accuracy` (IoU > 0.5) por √©poca

Estas curvas permiten identificar sobreajuste, convergencia y estabilidad.

```python
plt.plot(train_losses)
plt.plot(val_losses)
plt.plot(val_accuracies)
```

---

### ‚úÖ Resumen del Proceso de Transfer Learning

| Etapa                    | Acci√≥n realizada                                  |
|--------------------------|---------------------------------------------------|
| Modelo base              | Mask R-CNN (ResNet-50 + FPN)                      |
| Transfer Learning        | Se usaron pesos preentrenados en COCO            |
| Adaptaci√≥n de clases     | 3 clases (background, upper, lower)              |
| Entrenamiento parcial    | Backbone congelado, cabezas ajustadas            |
| Evaluaci√≥n               | IoU y p√©rdida sobre validaci√≥n y test            |
| Guardado de modelo       | Se guarda el modelo con menor `val_loss`         |
